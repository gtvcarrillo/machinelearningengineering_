{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52d63b8-c69d-4412-9aa9-6f76737dc4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# (opcional) criar a pastinha do pacote local\n",
    "import os\n",
    "os.makedirs(\"marathon\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0416a09b-0a6b-4969-89c2-dd06ee375477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paso 1 - Criando constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ff4249d-e7a6-467e-b419-b3202bbde1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing marathon/config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile marathon/config.py\n",
    "# -*- coding: utf-8 -*-\n",
    "D_MARATHON = 42195.0  # metros\n",
    "\n",
    "# Cortes por gênero (s)\n",
    "LIMIT_MEN_S   = 3 * 3600          # 3:00\n",
    "LIMIT_WOMEN_S = int(3.75 * 3600)  # 3:45\n",
    "\n",
    "# Regras de semanas\n",
    "LONG_RUN_TARGET_KM = 30.0\n",
    "LONG_RUN_INC_KM    = 2.0\n",
    "\n",
    "# Multiplicadores por faixa de esforço (com HR)\n",
    "EFFORT_MULT = {\"Já atinge\": 0.0, \"Baixo\": 1.0, \"Moderado\": 1.2, \"Alto\": 1.5}\n",
    "\n",
    "# Limites para slope (m/s por semana) e cap de semanas\n",
    "SLOPE_MIN, SLOPE_MAX = 0.01, 0.10\n",
    "WEEKS_CAP = 24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "654ff80b-24c7-4e6f-bb8f-0a81da66003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paso 2 - PRocessamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "473865d3-9bcb-4f53-89de-62b59568fa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting marathon/data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile marathon/data.py\n",
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from .config import D_MARATHON, LIMIT_MEN_S, LIMIT_WOMEN_S\n",
    "\n",
    "def load_raw(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    if df.shape[1] == 1 and \";\" in df.columns[0]:\n",
    "        cols = [c.strip() for c in df.columns[0].split(\";\")]\n",
    "        df = df.iloc[:, 0].str.split(\";\", expand=True)\n",
    "        df.columns = cols\n",
    "\n",
    "    rename = {\n",
    "        \"athlete\": \"athlete_id\",\n",
    "        \"gender\": \"gender\",\n",
    "        \"timestamp\": \"timestamp\",\n",
    "        \"distance (m)\": \"distance_m\",\n",
    "        \"elapsed time (s)\": \"elapsed_s\",\n",
    "        \"elevation gain (m)\": \"elev_gain_m\",\n",
    "        \"average heart rate (bpm)\": \"avg_hr_bpm\",\n",
    "    }\n",
    "    df = df.rename(columns={k: v for k, v in rename.items() if k in df.columns})\n",
    "\n",
    "    df[\"athlete_id\"] = df[\"athlete_id\"].astype(str)\n",
    "    for c in [\"distance_m\", \"elapsed_s\", \"elev_gain_m\", \"avg_hr_bpm\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c].astype(str).str.replace(\",\", \".\"), errors=\"coerce\")\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "    df = df.dropna(subset=[\"athlete_id\", \"timestamp\", \"distance_m\", \"elapsed_s\"]).copy()\n",
    "    df[\"km\"] = df[\"distance_m\"] / 1000.0\n",
    "    df[\"speed_mps\"] = df[\"distance_m\"] / df[\"elapsed_s\"]\n",
    "    df[\"pace_s_per_km\"] = df[\"elapsed_s\"] / df[\"km\"]\n",
    "    df = df[(df[\"km\"] > 0.5) & (df[\"pace_s_per_km\"].between(150, 1200))].copy()\n",
    "    return df\n",
    "\n",
    "def riegel_pred_seconds(distance_m, elapsed_s, exp: float = 1.06):\n",
    "    return elapsed_s * (D_MARATHON / distance_m) ** exp\n",
    "\n",
    "def aggregate_athlete(df_runs: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df_runs.copy()\n",
    "    df[\"pred_marathon_s_from_run\"] = riegel_pred_seconds(df[\"distance_m\"], df[\"elapsed_s\"])\n",
    "\n",
    "    mask10k = df[\"distance_m\"] >= 10000\n",
    "    best_pred = (df.loc[mask10k]\n",
    "                   .groupby(\"athlete_id\")[\"pred_marathon_s_from_run\"]\n",
    "                   .min()\n",
    "                   .rename(\"best_pred_marathon_s\"))\n",
    "\n",
    "    agg = (df.groupby(\"athlete_id\").agg(\n",
    "            gender=(\"gender\", lambda x: x.mode().iloc[0] if len(x.mode()) else \"U\"),\n",
    "            num_runs=(\"athlete_id\", \"size\"),\n",
    "            total_km=(\"km\", \"sum\"),\n",
    "            longest_run_km=(\"km\", \"max\"),\n",
    "            median_pace_s_per_km=(\"pace_s_per_km\", \"median\"),\n",
    "            best_pace_s_per_km=(\"pace_s_per_km\", \"min\"),\n",
    "            avg_hr_bpm=(\"avg_hr_bpm\", \"mean\"),\n",
    "            elev_gain_sum=(\"elev_gain_m\", \"sum\"),\n",
    "            share_runs_ge_15k=(\"km\", lambda s: (s >= 15).mean()),\n",
    "         )\n",
    "         .assign(mean_elev_gain_per_km=lambda d: d[\"elev_gain_sum\"] / d[\"total_km\"])\n",
    "         .drop(columns=[\"elev_gain_sum\"])\n",
    "         .reset_index()\n",
    "         .merge(best_pred.reset_index(), on=\"athlete_id\", how=\"left\")\n",
    "    )\n",
    "\n",
    "    agg[\"gender\"] = agg[\"gender\"].astype(str).str.upper().str.strip()\n",
    "    agg[\"target_s_gender\"] = np.where(agg[\"gender\"].str.startswith(\"M\"), LIMIT_MEN_S, LIMIT_WOMEN_S)\n",
    "    agg[\"v_pred_mps\"]   = D_MARATHON / agg[\"best_pred_marathon_s\"]\n",
    "    agg[\"v_needed_mps\"] = D_MARATHON / agg[\"target_s_gender\"]\n",
    "    agg[\"apto_genero\"] = (agg[\"best_pred_marathon_s\"] <= agg[\"target_s_gender\"]).astype(int)\n",
    "    agg[\"esforco_extra_pct_genero\"] = ((agg[\"v_needed_mps\"] - agg[\"v_pred_mps\"]) / agg[\"v_pred_mps\"]) * 100\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6876967b-d850-48df-883e-7824f33d4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 3 — marathon/effort.py (HR e esforço)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1a30bbd-b39e-42ad-a09c-39e8eb1cc91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing marathon/effort.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile marathon/effort.py\n",
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def fit_hr_speed(df_runs: pd.DataFrame) -> pd.DataFrame:\n",
    "    flt = df_runs[(df_runs[\"avg_hr_bpm\"].notna()) & (df_runs[\"km\"].between(8.0, 25.0))].copy()\n",
    "    flt = flt.sort_values([\"athlete_id\", \"timestamp\"])\n",
    "\n",
    "    def _fit(g: pd.DataFrame):\n",
    "        x = g[\"speed_mps\"].values\n",
    "        y = g[\"avg_hr_bpm\"].values\n",
    "        if len(x) < 3 or np.allclose(x, x[0]) or np.any(~np.isfinite(y)):\n",
    "            return pd.Series({\"a_int\": np.nan, \"b_slope\": np.nan, \"hr_p50\": np.nan, \"hr_p80\": np.nan, \"hr_p90\": np.nan})\n",
    "        try:\n",
    "            b, a = np.polyfit(x, y, 1)  # HR = a + b*vel\n",
    "            return pd.Series({\n",
    "                \"a_int\": float(a),\n",
    "                \"b_slope\": float(b),\n",
    "                \"hr_p50\": float(np.percentile(y, 50)),\n",
    "                \"hr_p80\": float(np.percentile(y, 80)),\n",
    "                \"hr_p90\": float(np.percentile(y, 90)),\n",
    "            })\n",
    "        except Exception:\n",
    "            return pd.Series({\"a_int\": np.nan, \"b_slope\": np.nan, \"hr_p50\": np.nan, \"hr_p80\": np.nan, \"hr_p90\": np.nan})\n",
    "\n",
    "    fits = flt.groupby(\"athlete_id\").apply(_fit).reset_index()\n",
    "    for c in [\"a_int\", \"b_slope\", \"hr_p50\", \"hr_p80\", \"hr_p90\"]:\n",
    "        med = fits[c].median(skipna=True)\n",
    "        fits[c] = fits[c].fillna(med)\n",
    "    return fits\n",
    "\n",
    "def classify_effort_with_hr(agg: pd.DataFrame, fits: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = agg.merge(fits, on=\"athlete_id\", how=\"left\")\n",
    "    df[\"hr_needed_bpm\"] = df[\"a_int\"] + df[\"b_slope\"] * df[\"v_needed_mps\"]\n",
    "\n",
    "    def _cls(row):\n",
    "        if row[\"apto_genero\"] == 1:\n",
    "            return \"Já atinge\"\n",
    "        gap = row[\"esforco_extra_pct_genero\"]\n",
    "        hrn, p80, p90 = row[\"hr_needed_bpm\"], row[\"hr_p80\"], row[\"hr_p90\"]\n",
    "        if (gap < 5) and (hrn <= p80):\n",
    "            return \"Baixo\"\n",
    "        if (5 <= gap <= 15) or (p80 < hrn <= p90):\n",
    "            return \"Moderado\"\n",
    "        return \"Alto\"\n",
    "\n",
    "    df[\"esforco_genero_hr\"] = df.apply(_cls, axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babeabff-7729-48b9-8ce9-a4639d0250b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 4 — marathon/weeks.py (semanas e slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d496c83-1630-48ea-9376-e2975e7aa902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing marathon/weeks.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile marathon/weeks.py\n",
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from .config import LONG_RUN_TARGET_KM, LONG_RUN_INC_KM, SLOPE_MIN, SLOPE_MAX, WEEKS_CAP\n",
    "\n",
    "def estimate_speed_slope_weeks(df_runs: pd.DataFrame) -> pd.DataFrame:\n",
    "    flt = df_runs[(df_runs[\"km\"].between(8.0, 25.0))].copy().sort_values([\"athlete_id\", \"timestamp\"])\n",
    "    first = flt.groupby(\"athlete_id\")[\"timestamp\"].transform(\"min\")\n",
    "    flt[\"weeks_since_first\"] = (flt[\"timestamp\"] - first).dt.days / 7.0\n",
    "\n",
    "    def _slope(g: pd.DataFrame):\n",
    "        if g.shape[0] < 2:\n",
    "            return np.nan\n",
    "        x = g[\"weeks_since_first\"].values\n",
    "        y = g[\"speed_mps\"].values\n",
    "        if np.allclose(x, x[0]): return np.nan\n",
    "        k, b = np.polyfit(x, y, 1)\n",
    "        return k\n",
    "\n",
    "    slopes = flt.groupby(\"athlete_id\").apply(_slope).rename(\"slope_speed_mps_per_week\").reset_index()\n",
    "    med = slopes[\"slope_speed_mps_per_week\"].median(skipna=True)\n",
    "    slopes[\"slope_speed_mps_per_week\"] = slopes[\"slope_speed_mps_per_week\"].fillna(med).clip(SLOPE_MIN, SLOPE_MAX)\n",
    "    return slopes\n",
    "\n",
    "def estimate_weeks_to_target(df_effort_hr: pd.DataFrame, slopes: pd.DataFrame, effort_mult_map: dict) -> pd.DataFrame:\n",
    "    df = df_effort_hr.merge(slopes, on=\"athlete_id\", how=\"left\")\n",
    "    med = df[\"slope_speed_mps_per_week\"].median(skipna=True)\n",
    "    df[\"slope_speed_mps_per_week\"] = df[\"slope_speed_mps_per_week\"].fillna(med).clip(SLOPE_MIN, SLOPE_MAX)\n",
    "\n",
    "    v_pred = df[\"v_pred_mps\"].fillna(0.0)\n",
    "    df[\"delta_v_needed\"] = (df[\"v_needed_mps\"] - v_pred).clip(lower=0)\n",
    "\n",
    "    eps = 1e-6\n",
    "    df[\"weeks_speed_goal\"] = df[\"delta_v_needed\"] / (df[\"slope_speed_mps_per_week\"] + eps)\n",
    "\n",
    "    lr = df[\"longest_run_km\"].fillna(0.0)\n",
    "    df[\"weeks_long_run\"] = np.ceil(np.clip((LONG_RUN_TARGET_KM - lr) / LONG_RUN_INC_KM, a_min=0, a_max=None))\n",
    "\n",
    "    df[\"mult_effort_hr\"] = df[\"esforco_genero_hr\"].map(effort_mult_map).fillna(effort_mult_map[\"Moderado\"])\n",
    "    base_weeks = np.maximum(df[\"weeks_speed_goal\"], df[\"weeks_long_run\"])\n",
    "    df[\"weeks_to_target_genero_est_hr\"] = np.ceil(np.clip(base_weeks * df[\"mult_effort_hr\"], 0, WEEKS_CAP))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b22f9d1-43a5-4f6b-bbbd-a70d3fe8acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 5 — marathon/modeling.py (treino + gráficos + métricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca932388-8a9b-4cec-a1d3-2c495354d62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing marathon/modeling.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile marathon/modeling.py\n",
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, confusion_matrix, precision_recall_curve)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import joblib\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    HAS_LGBM = True\n",
    "except Exception:\n",
    "    HAS_LGBM = False\n",
    "\n",
    "def _ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _plot_feature_importance(names, importances, out_path: Path, top_n: int = 20, title: str = \"Importância de variáveis\"):\n",
    "    idx = np.argsort(importances)[::-1][:top_n]\n",
    "    names = np.array(names)[idx]; vals = np.array(importances)[idx]\n",
    "    plt.figure(figsize=(8, max(4, len(idx)*0.3)))\n",
    "    plt.barh(range(len(idx)), vals[::-1])\n",
    "    plt.yticks(range(len(idx)), names[::-1])\n",
    "    plt.xlabel(\"Importância\"); plt.title(title); plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def _plot_confusion(y_true, y_pred, out_path: Path, title: str):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    im = ax.imshow(cm, cmap=\"Blues\")\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=[0,1], yticks=[0,1], xticklabels=[\"0\",\"1\"], yticklabels=[\"0\",\"1\"],\n",
    "           ylabel=\"Verdadeiro\", xlabel=\"Previsto\", title=title)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "    plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def _plot_auc_over_time(dates, y_true, y_score, out_path: Path, n_bins: int = 10, title: str = \"AUC ao longo do tempo\"):\n",
    "    order = np.argsort(dates)\n",
    "    dates_ord = np.array(dates)[order]; y_ord = np.array(y_true)[order]; s_ord = np.array(y_score)[order]\n",
    "    xs, aucs = [], []\n",
    "    for k in range(max(2, n_bins)):\n",
    "        end = int(len(y_ord) * (k+1) / n_bins)\n",
    "        if end < 2: continue\n",
    "        try:\n",
    "            auc = roc_auc_score(y_ord[:end], s_ord[:end])\n",
    "            aucs.append(auc); xs.append(dates_ord[end-1])\n",
    "        except Exception:\n",
    "            pass\n",
    "    plt.figure(figsize=(7,3.5))\n",
    "    plt.plot(xs, aucs, marker=\"o\")\n",
    "    plt.title(title); plt.ylabel(\"AUC\"); plt.xlabel(\"Tempo (ordem dos atletas)\")\n",
    "    plt.grid(True, alpha=0.3); plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def _plot_precision_recall_over_time(dates, y_true, y_score, thr: float, out_path: Path, n_bins: int = 10, title: str = \"Precision e Recall ao longo do tempo\"):\n",
    "    order = np.argsort(dates)\n",
    "    dates_ord = np.array(dates)[order]; y_ord = np.array(y_true)[order]; s_ord = np.array(y_score)[order]\n",
    "    precs, recs, xs = [], [], []\n",
    "    for k in range(max(2, n_bins)):\n",
    "        end = int(len(y_ord) * (k+1) / n_bins)\n",
    "        if end < 2: continue\n",
    "        yp = (s_ord[:end] >= thr).astype(int)\n",
    "        tp = (yp & (y_ord[:end]==1)).sum(); fp = (yp & (y_ord[:end]==0)).sum(); fn = ((1-yp) & (y_ord[:end]==1)).sum()\n",
    "        prec = tp / (tp+fp) if (tp+fp)>0 else 0.0\n",
    "        rec = tp / (tp+fn) if (tp+fn)>0 else 0.0\n",
    "        precs.append(prec); recs.append(rec); xs.append(dates_ord[end-1])\n",
    "    plt.figure(figsize=(7,3.5))\n",
    "    plt.plot(xs, precs, marker=\"o\", label=\"Precision\")\n",
    "    plt.plot(xs, recs, marker=\"o\", label=\"Recall\")\n",
    "    plt.legend(); plt.title(title); plt.ylim(0,1); plt.xlabel(\"Tempo\")\n",
    "    plt.grid(True, alpha=0.3); plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def train_apto_classifier(df_agg_hr: pd.DataFrame, out_dir: Path, runs_df: pd.DataFrame) -> dict:\n",
    "    _ensure_dir(out_dir)\n",
    "    target = \"apto_genero\"\n",
    "    feat_all = [\n",
    "        \"gender\",\"num_runs\",\"total_km\",\"longest_run_km\",\n",
    "        \"median_pace_s_per_km\",\"best_pace_s_per_km\",\"avg_hr_bpm\",\n",
    "        \"mean_elev_gain_per_km\",\"share_runs_ge_15k\",\"best_pred_marathon_s\"\n",
    "    ]\n",
    "\n",
    "    # v1) Processamento dos Dados\n",
    "    df = df_agg_hr.dropna(subset=[target]).copy()\n",
    "    runs_df = runs_df.copy()\n",
    "    runs_df[\"timestamp\"] = pd.to_datetime(runs_df[\"timestamp\"], errors=\"coerce\")\n",
    "    first_ts = runs_df.groupby(\"athlete_id\")[\"timestamp\"].min().rename(\"first_timestamp\")\n",
    "    df = df.merge(first_ts.reset_index(), on=\"athlete_id\", how=\"left\")\n",
    "\n",
    "    # 2) Split Treino/Val/Teste\n",
    "    X = df[feat_all].copy(); y = df[target].astype(int).values\n",
    "    pre = ColumnTransformer([(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"gender\"])], remainder=\"passthrough\")\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, stratify=y_train_full, random_state=42)\n",
    "\n",
    "    # 3) Seleção de Variáveis (model-based)\n",
    "    base_clf = (lgb.LGBMClassifier(objective=\"binary\", n_estimators=600, learning_rate=0.03,\n",
    "                                   num_leaves=63, subsample=0.8, colsample_bytree=0.8,\n",
    "                                   class_weight=\"balanced\", random_state=42)\n",
    "                if HAS_LGBM else\n",
    "                RandomForestClassifier(n_estimators=400, class_weight=\"balanced_subsample\", random_state=42, n_jobs=-1))\n",
    "    base_pipe = Pipeline([(\"prep\", pre), (\"clf\", base_clf)])\n",
    "    base_pipe.fit(X_train, y_train)\n",
    "    feat_names = list(base_pipe.named_steps[\"prep\"].get_feature_names_out())\n",
    "    selector = SelectFromModel(base_pipe.named_steps[\"clf\"], prefit=True, threshold=\"median\")\n",
    "    X_train_sel = selector.transform(base_pipe.named_steps[\"prep\"].transform(X_train))\n",
    "    X_val_sel   = selector.transform(base_pipe.named_steps[\"prep\"].transform(X_val))\n",
    "    X_test_sel  = selector.transform(base_pipe.named_steps[\"prep\"].transform(X_test))\n",
    "\n",
    "    # 4) Treinamento Final + 4.1 Importância\n",
    "    final_clf = (lgb.LGBMClassifier(objective=\"binary\", n_estimators=800, learning_rate=0.03,\n",
    "                                    num_leaves=63, subsample=0.8, colsample_bytree=0.8,\n",
    "                                    class_weight=\"balanced\", random_state=42)\n",
    "                 if HAS_LGBM else\n",
    "                 RandomForestClassifier(n_estimators=600, class_weight=\"balanced_subsample\", random_state=42, n_jobs=-1))\n",
    "    final_clf.fit(X_train_sel, y_train)\n",
    "    imp = final_clf.feature_importances_\n",
    "    sel_names = np.array(feat_names)[selector.get_support()]\n",
    "    pd.DataFrame({\"feature\": sel_names, \"importance\": imp}).sort_values(\"importance\", ascending=False)\\\n",
    "      .to_csv(out_dir / \"feature_importance.csv\", index=False)\n",
    "    _plot_feature_importance(sel_names, imp, out_dir / \"feature_importance.png\")\n",
    "\n",
    "    # Scores (probas)\n",
    "    proba = (lambda clf, X: clf.predict_proba(X)[:,1] if hasattr(clf,\"predict_proba\") else clf.decision_function(X))\n",
    "    s_train, s_val, s_test = proba(final_clf, X_train_sel), proba(final_clf, X_val_sel), proba(final_clf, X_test_sel)\n",
    "\n",
    "    # 5.4) Ajuste de Score (threshold) por F1 na validação\n",
    "    thr_grid = np.linspace(0.1, 0.9, 81)\n",
    "    best_thr, best_f1 = 0.5, -1\n",
    "    for t in thr_grid:\n",
    "        yp = (s_val >= t).astype(int)\n",
    "        f1 = f1_score(y_val, yp, zero_division=0)\n",
    "        if f1 > best_f1: best_f1, best_thr = f1, t\n",
    "\n",
    "    # 5.4.1 Validação (métricas + matriz confusão)\n",
    "    y_val_pred = (s_val >= best_thr).astype(int)\n",
    "    val_metrics = {\n",
    "        \"roc_auc\": float(roc_auc_score(y_val, s_val)),\n",
    "        \"accuracy\": float(accuracy_score(y_val, y_val_pred)),\n",
    "        \"precision\": float(precision_score(y_val, y_val_pred, zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_val, y_val_pred, zero_division=0)),\n",
    "        \"f1\": float(f1_score(y_val, y_val_pred, zero_division=0)),\n",
    "        \"threshold\": float(best_thr)\n",
    "    }\n",
    "    _plot_confusion(y_val, y_val_pred, out_dir / \"cm_validation.png\", \"Matriz de Confusão – Validação\")\n",
    "\n",
    "    # 5.4.2 Teste\n",
    "    y_test_pred = (s_test >= best_thr).astype(int)\n",
    "    test_metrics = {\n",
    "        \"roc_auc\": float(roc_auc_score(y_test, s_test)),\n",
    "        \"accuracy\": float(accuracy_score(y_test, y_test_pred)),\n",
    "        \"precision\": float(precision_score(y_test, y_test_pred, zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_test, y_test_pred, zero_division=0)),\n",
    "        \"f1\": float(f1_score(y_test, y_test_pred, zero_division=0)),\n",
    "        \"threshold\": float(best_thr)\n",
    "    }\n",
    "    _plot_confusion(y_test, y_test_pred, out_dir / \"cm_test.png\", \"Matriz de Confusão – Teste\")\n",
    "\n",
    "    # 5.2/5.3 AUC / Precision-Recall ao longo do tempo (usa first_timestamp)\n",
    "    df_train = df.iloc[X_train.index].copy(); df_val = df.iloc[X_val.index].copy(); df_test = df.iloc[X_test.index].copy()\n",
    "    for d in [df_val, df_test]:\n",
    "        if d[\"first_timestamp\"].isna().any():\n",
    "            # fallback determinístico\n",
    "            d.loc[d[\"first_timestamp\"].isna(), \"first_timestamp\"] = pd.date_range(\"2000-01-01\", periods=d[\"first_timestamp\"].isna().sum(), freq=\"D\")\n",
    "\n",
    "    _plot_auc_over_time(df_val[\"first_timestamp\"], y_val, s_val, out_dir / \"auc_over_time_val.png\", title=\"AUC ao longo do tempo – Validação\")\n",
    "    _plot_auc_over_time(df_test[\"first_timestamp\"], y_test, s_test, out_dir / \"auc_over_time_test.png\", title=\"AUC ao longo do tempo – Teste\")\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    def _pr_curve_to_df(y_true, scores):\n",
    "        prec, rec, thr = precision_recall_curve(y_true, scores)\n",
    "        thr_full = np.r_[thr, 1.0]\n",
    "        return pd.DataFrame({\"threshold\": thr_full, \"precision\": prec, \"recall\": rec})\n",
    "    pr_val_df = _pr_curve_to_df(y_val, s_val); pr_test_df = _pr_curve_to_df(y_test, s_test)\n",
    "    pr_val_df.to_csv(out_dir / \"precision_recall_curve_val.csv\", index=False)\n",
    "    pr_test_df.to_csv(out_dir / \"precision_recall_curve_test.csv\", index=False)\n",
    "\n",
    "    # Bundle do modelo\n",
    "    bundle = {\n",
    "        \"prep\": base_pipe.named_steps[\"prep\"],\n",
    "        \"selector\": selector,\n",
    "        \"model\": final_clf,\n",
    "        \"threshold\": best_thr,\n",
    "        \"selected_feature_names\": sel_names.tolist(),\n",
    "        \"val_metrics\": val_metrics,\n",
    "        \"test_metrics\": test_metrics,\n",
    "    }\n",
    "    joblib.dump(bundle, out_dir / \"model_apto_genero_bundle.pkl\")\n",
    "\n",
    "    # Resumo PR\n",
    "    def _metrics_from_scores(y_true, scores, thr):\n",
    "        y_pred = (scores >= thr).astype(int)\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        tp = int((y_pred & (y_true==1)).sum())\n",
    "        fp = int((y_pred & (y_true==0)).sum())\n",
    "        fn = int(((1-y_pred) & (y_true==1)).sum())\n",
    "        tn = int(((1-y_pred) & (y_true==0)).sum())\n",
    "        from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "        return {\"threshold\": float(thr),\n",
    "                \"precision\": float(precision_score(y_true, y_pred, zero_division=0)),\n",
    "                \"recall\": float(recall_score(y_true, y_pred, zero_division=0)),\n",
    "                \"f1\": float(f1_score(y_true, y_pred, zero_division=0)),\n",
    "                \"tp\": tp, \"fp\": fp, \"fn\": fn, \"tn\": tn}\n",
    "    pr_summary = pd.DataFrame([{\"split\":\"validação\", **_metrics_from_scores(y_val, s_val, best_thr)},\n",
    "                               {\"split\":\"teste\",     **_metrics_from_scores(y_test, s_test, best_thr)}])\n",
    "    pr_summary.to_csv(out_dir / \"precision_recall_summary.csv\", index=False)\n",
    "\n",
    "    return {\"model_path\": str(out_dir / \"model_apto_genero_bundle.pkl\"),\n",
    "            \"val_metrics\": val_metrics, \"test_metrics\": test_metrics}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3327f0c8-bb19-4bd8-bd5f-3f74ea0dcbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 6 — marathon/pipeline.py (orquestra tudo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f190afb2-2f10-480a-a050-4c776dacfc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing marathon/pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile marathon/pipeline.py\n",
    "# -*- coding: utf-8 -*-\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from .config import EFFORT_MULT\n",
    "from .data import load_raw, aggregate_athlete\n",
    "from .effort import fit_hr_speed, classify_effort_with_hr\n",
    "from .weeks import estimate_speed_slope_weeks, estimate_weeks_to_target\n",
    "from .modeling import train_apto_classifier\n",
    "\n",
    "def distributions(df_final: pd.DataFrame) -> dict:\n",
    "    N = len(df_final)\n",
    "    apto = df_final[\"apto_genero\"].map({1:\"Sim\",0:\"Não\"}).value_counts()\n",
    "    effort = df_final[\"esforco_genero_hr\"].value_counts()\n",
    "    def bucket(w):\n",
    "        if pd.isna(w): return \"Sem estimativa\"\n",
    "        w = int(w)\n",
    "        if w == 0: return \"0 (já atinge)\"\n",
    "        if 1 <= w <= 4: return \"1–4\"\n",
    "        if 5 <= w <= 8: return \"5–8\"\n",
    "        if 9 <= w <= 12: return \"9–12\"\n",
    "        if 13 <= w <= 16: return \"13–16\"\n",
    "        if 17 <= w <= 20: return \"17–20\"\n",
    "        return \"21–24\"\n",
    "    weeks = df_final[\"weeks_to_target_genero_est_hr\"].apply(bucket).value_counts()\n",
    "    return {\n",
    "        \"total\": N,\n",
    "        \"apto\": {k:int(v) for k,v in apto.items()},\n",
    "        \"esforco\": {k:int(v) for k,v in effort.items()},\n",
    "        \"semanas\": {k:int(weeks.get(k,0)) for k in [\"0 (já atinge)\",\"1–4\",\"5–8\",\"9–12\",\"13–16\",\"17–20\",\"21–24\",\"Sem estimativa\"]}\n",
    "    }\n",
    "\n",
    "def run_pipeline(raw_path: str, out_dir: str, train_model: bool = True):\n",
    "    out_dir = Path(out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    runs = load_raw(raw_path)\n",
    "\n",
    "    agg = aggregate_athlete(runs)\n",
    "    agg.to_csv(out_dir / \"athlete_features_gender.csv\", index=False)\n",
    "\n",
    "    fits = fit_hr_speed(runs)\n",
    "    agg_hr = classify_effort_with_hr(agg, fits)\n",
    "    agg_hr.to_csv(out_dir / \"athlete_features_gender_hr.csv\", index=False)\n",
    "\n",
    "    slopes = estimate_speed_slope_weeks(runs)\n",
    "    final = estimate_weeks_to_target(agg_hr, slopes, EFFORT_MULT)\n",
    "\n",
    "    keep = [\"athlete_id\",\"gender\",\"apto_genero\",\"esforco_genero_hr\",\n",
    "            \"best_pred_marathon_s\",\"target_s_gender\",\n",
    "            \"v_pred_mps\",\"v_needed_mps\",\"esforco_extra_pct_genero\",\n",
    "            \"hr_p80\",\"hr_p90\",\"hr_needed_bpm\",\n",
    "            \"num_runs\",\"total_km\",\"longest_run_km\",\"median_pace_s_per_km\",\"best_pace_s_per_km\",\"avg_hr_bpm\",\n",
    "            \"mean_elev_gain_per_km\",\"share_runs_ge_15k\",\n",
    "            \"slope_speed_mps_per_week\",\"weeks_speed_goal\",\"weeks_long_run\",\"weeks_to_target_genero_est_hr\"]\n",
    "    final[keep].to_csv(out_dir / \"athlete_final_weeks_gender_hr.csv\", index=False)\n",
    "\n",
    "    summary = distributions(final)\n",
    "    (out_dir / \"summary.json\").write_text(json.dumps(summary, indent=2, ensure_ascii=False))\n",
    "\n",
    "    model_info = None\n",
    "    if train_model:\n",
    "        model_info = train_apto_classifier(agg_hr, out_dir, runs)\n",
    "\n",
    "    return summary, model_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44045f7a-4956-4e79-b62f-6c9558012dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 7 — Usar no notebook (executar pipeline por partes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fef40fd-37ca-4403-8e41-d0045a00da2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'total': 116,\n",
       "  'apto': {'Não': 59, 'Sim': 57},\n",
       "  'esforco': {'Já atinge': 57, 'Moderado': 35, 'Alto': 20, 'Baixo': 4},\n",
       "  'semanas': {'0 (já atinge)': 57,\n",
       "   '1–4': 3,\n",
       "   '5–8': 2,\n",
       "   '9–12': 3,\n",
       "   '13–16': 3,\n",
       "   '17–20': 1,\n",
       "   '21–24': 47,\n",
       "   'Sem estimativa': 0}},\n",
       " {'model_path': 'C:\\\\Users\\\\gtvca\\\\Documents\\\\output\\\\model_apto_genero_bundle.pkl',\n",
       "  'val_metrics': {'roc_auc': 0.8636363636363635,\n",
       "   'accuracy': 0.782608695652174,\n",
       "   'precision': 0.6875,\n",
       "   'recall': 1.0,\n",
       "   'f1': 0.8148148148148148,\n",
       "   'threshold': 0.18},\n",
       "  'test_metrics': {'roc_auc': 0.9027777777777778,\n",
       "   'accuracy': 0.7916666666666666,\n",
       "   'precision': 0.7692307692307693,\n",
       "   'recall': 0.8333333333333334,\n",
       "   'f1': 0.8,\n",
       "   'threshold': 0.18}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from marathon.pipeline import run_pipeline\n",
    "\n",
    "summary, model_info = run_pipeline(\n",
    "    raw_path=r\"C:\\Users\\gtvca\\Documents\\raw-data-kaggle.csv\",\n",
    "    out_dir=r\"C:\\Users\\gtvca\\Documents\\output\",\n",
    "    train_model=True\n",
    ")\n",
    "\n",
    "summary, model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88703c9-45f9-442d-a226-d40003bd5573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
