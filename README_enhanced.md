# Projeto ML â€“ Maratona: AptidÃ£o, EsforÃ§o (FC) e Semanas de Treino

Este repositÃ³rio traz um pipeline que:
1) **Classifica aptidÃ£o** para completar a maratona em **3h (M)** / **3h45 (F)**;  
2) **Estima esforÃ§o fisiolÃ³gico** com base em **frequÃªncia cardÃ­aca (FC)**;  
3) **PrevÃª semanas de treino** necessÃ¡rias para atingir o alvo.

---

## ğŸ§  Modelos Utilizados (com clareza)

### 1) Componentes determinÃ­sticos (sem treino)
- **FÃ³rmula de Riegel**: projeta tempo de maratona a partir de um treino. Ã‰ uma relaÃ§Ã£o empÃ­rica:
  \[
    \hat{T}_{42k} = T_{treino} \cdot \left(\frac{42.195}{dist_{treino}}\right)^{1.06}
  \]
  Usamos o **menor** tempo projetado entre treinos â‰¥10 km (por atleta): `best_pred_marathon_s`.

- **Regras de esforÃ§o (`esforco_genero_hr`)**: combinam  
  (a) o **gap de velocidade** atÃ© o alvo por gÃªnero e  
  (b) a **FC necessÃ¡ria** para correr nessa velocidade, comparada a **percentis pessoais** (P80/P90) de FC.  
  Resultado categÃ³rico: **JÃ¡ atinge / Baixo / Moderado / Alto**.

### 2) RegressÃµes individuais (por atleta)
- **HR ~ velocidade** (linear): estima `a_int` e `b_slope` para prever a FC na velocidade-alvo (`hr_needed_bpm`).
- **Velocidade ~ tempo** (semanas) (linear): estima a **inclinaÃ§Ã£o de melhora** `slope_speed_mps_per_week` (m/s por semana).

> Essas regressÃµes nÃ£o â€œcomparamâ€ atletas entre si: sÃ£o **curvas pessoais** para traduzir histÃ³rico em esforÃ§o e ritmo de evoluÃ§Ã£o.

### 3) Classificador de aptidÃ£o (opcional, supervisionado)
- **Algoritmo principal**: **LightGBM** (Gradient Boosted Decision Trees);  
  **Fallback**: **RandomForest**, caso LightGBM nÃ£o esteja instalado.
- **PrÃ©-processamento**: One-Hot Encoding apenas em `gender`.
- **SeleÃ§Ã£o de variÃ¡veis**: `SelectFromModel` com **limiar pela mediana** das importÃ¢ncias de um modelo-base.
- **Ajuste operacional**: busca de **threshold** no intervalo [0.1, 0.9] para **maximizar F1** na *validaÃ§Ã£o* e aplicaÃ§Ã£o desse threshold no *teste*.
- **MÃ©tricas**: ROC AUC, Accuracy, Precision, Recall, F1; matrizes de confusÃ£o; AUC/Precision/Recall **ao longo do tempo** (robustez temporal).

---

## ğŸ”¢ MÃ©tricas do Modelo & InterpretaÃ§Ã£o

> Substitua os valores abaixo pelos **seus resultados** (gerados no `output/`):
> - `precision_recall_summary.csv` (Precision, Recall, F1 por split)
> - `model_apto_genero_bundle.pkl` (contÃ©m AUC de validaÃ§Ã£o e teste)

### Resumo NumÃ©rico (preencha)
| Split      | Precision | Recall | F1  | AUC  | Threshold |
|------------|-----------|--------|-----|------|-----------|
| ValidaÃ§Ã£o  | 0.XX      | 0.XX   | 0.XX| 0.XX | 0.XX      |
| Teste      | 0.XX      | 0.XX   | 0.XX| 0.XX | 0.XX      |

**Como interpretar:**
- **Precision**: dos identificados como aptos, quantos realmente sÃ£o. Alta precisÃ£o â†’ poucos falsos aptos.
- **Recall**: dos realmente aptos, quantos o modelo identifica. Alto recall â†’ poucos aptos â€œperdidosâ€.
- **F1**: equilÃ­brio entre Precision e Recall (bom para cenÃ¡rios sem preferÃªncia clara).
- **ROC AUC**: capacidade do score em ordenar aptos vs nÃ£o aptos, **independente do threshold**.
- **Threshold**: ponto operacional escolhido (otimizado por F1).  
  Ajuste conforme sua polÃ­tica:
  - Foco em **nÃ£o perder aptos** â†’ **reduza** o threshold (â†‘ Recall, â†“ Precision);
  - Foco em **evitar falsos aptos** â†’ **aumente** o threshold (â†‘ Precision, â†“ Recall).

### Gaps de generalizaÃ§Ã£o (val â†’ teste)
- Idealmente **â‰¤ 0,05** em **AUC** e **F1**.  
  Gaps maiores sugerem **overfitting** ou **mudanÃ§a de distribuiÃ§Ã£o** (drift).

### Curvas e GrÃ¡ficos (o que observar)
- **Matriz de ConfusÃ£o (Val/Teste)**: padrÃ£o de erros (FP vs FN).
- **AUC ao longo do tempo**: estabilidade temporal; quedas podem indicar drift.
- **Precision & Recall ao longo do tempo**: comportamento operacional em janelas de tempo.

> Registre em 1â€“2 parÃ¡grafos o â€œvereditoâ€:  
> - Se AUC_test â‰¥ 0.80 e F1_test â‰¥ 0.70, e gaps pequenos â†’ **modelo eficiente**.  
> - Caso contrÃ¡rio â†’ ajustar threshold e/ou enriquecer features.

---

## ğŸ” InterpretaÃ§Ã£o das VariÃ¡veis

### DireÃ§Ã£o de impacto (intuitiva)
- **Capacidade atual**
  - `best_pred_marathon_s` (s): **menor** (melhor) â†’ mais apto.
  - `best_pace_s_per_km` / `median_pace_s_per_km` (s/km): **menor** (ritmo mais rÃ¡pido) â†’ mais apto.
- **Volume**
  - `total_km`, `num_runs`: **maiores** costumam indicar base melhor â†’ maior probabilidade de aptidÃ£o.
  - `longest_run_km`: **maior** sugere capacidade para longÃµes â†’ favorece aptidÃ£o.
- **Terreno**
  - `mean_elev_gain_per_km`: **maior** indica treinos mais duros; pode sinalizar boa forÃ§a/ resistÃªncia, mas depende do contexto.
- **Cardio**
  - `avg_hr_bpm`: valores muito altos crÃ´nicos podem indicar treinos sempre duros; interpretaÃ§Ã£o depende do atleta (por isso usamos percentis pessoais).
- **Estrutura de treinos**
  - `share_runs_ge_15k`: **maior** indica consistÃªncia de longos â†’ favorece aptidÃ£o.

### VariÃ¡veis de esforÃ§o (com FC)
- `a_int`, `b_slope`: descrevem a **curva pessoal** HR~velocidade.
- `hr_p80`, `hr_p90`: **marcos pessoais** de esforÃ§o.
- `hr_needed_bpm`: FC estimada para correr na **velocidade-alvo**.
- `esforco_genero_hr`:  
  - **JÃ¡ atinge**: sem esforÃ§o adicional;  
  - **Baixo**: gap<5% e HRâ‰¤P80 (ajustes finos);  
  - **Moderado**: 5â€“15% **ou** HR entre P80â€“P90;  
  - **Alto**: >15% **ou** HR>P90 (exigÃªncia alta).

### Semanas de treino
- `slope_speed_mps_per_week`: melhora semanal esperada (m/s/sem).
- `weeks_speed_goal`: semanas para fechar **gap de velocidade**.
- `weeks_long_run`: semanas para elevar **longÃ£o** atÃ© 30 km (+2 km/sem).
- `weeks_to_target_genero_est_hr`: mÃ¡ximo entre as duas, **ajustado** pela dureza de esforÃ§o (multiplicador), **capado** em 24 semanas.

---

## ğŸ§¾ Artefatos gerados (pasta `output/`)

- **Tabelas por atleta**:  
  `athlete_features_gender.csv`, `athlete_features_gender_hr.csv`, `athlete_final_weeks_gender_hr.csv`
- **Resumo**: `summary.json`
- **Modelagem (se `--train_model`)**:
  - `feature_importance.csv`, `feature_importance.png`
  - `cm_validation.png`, `cm_test.png`
  - `auc_over_time_val.png`, `auc_over_time_test.png`
  - `pr_over_time_val.png`, `pr_over_time_test.png`
  - `precision_recall_summary.csv`
  - `precision_recall_curve_val.csv`, `precision_recall_curve_test.csv`
  - `model_apto_genero_bundle.pkl`

---

## ğŸ§ª Como preencher automaticamente a seÃ§Ã£o de mÃ©tricas

No Jupyter, rode:

```python
import json, pandas as pd, joblib
from pathlib import Path

OUT_DIR = Path(r"C:/Users/SEU_USUARIO/Documents/output")

pr = pd.read_csv(OUT_DIR / "precision_recall_summary.csv")
val = pr[pr["split"]=="validaÃ§Ã£o"].iloc[0]
tst = pr[pr["split"]=="teste"].iloc[0]

try:
    bundle = joblib.load(OUT_DIR / "model_apto_genero_bundle.pkl")
    auc_val = bundle["val_metrics"]["roc_auc"]
    auc_tst = bundle["test_metrics"]["roc_auc"]
except Exception:
    auc_val = auc_tst = float("nan")

print("Tabela para colar no README:")
print(f"| ValidaÃ§Ã£o | {val['precision']:.3f} | {val['recall']:.3f} | {val['f1']:.3f} | {auc_val:.3f} | {val['threshold']:.2f} |")
print(f"| Teste     | {tst['precision']:.3f} | {tst['recall']:.3f} | {tst['f1']:.3f} | {auc_tst:.3f} | {tst['threshold']:.2f} |")
```

---

## âš ï¸ LimitaÃ§Ãµes e PrÃ³ximos Passos

- **Riegel** Ã© proxy populacional; validaÃ§Ã£o com provas/referÃªncias Ã© desejÃ¡vel.
- **FC sem idade** usa percentis pessoais (P80/P90); qualidade de HR influencia.
- **Slope linear** simplifica evoluÃ§Ã£o; ciclos/lesÃµes podem alterar.
- Melhorias: enriquecer features (consistÃªncia semanal, % tempo HR>P80, variaÃ§Ã£o de ritmo, ganho normalizado), **cross-validation** e **HPO** (LightGBM).

---

## ğŸ“ CrÃ©ditos

- Estrutura inspirada em notebook de referÃªncia compartilhado.
- ImplementaÃ§Ã£o e documentaÃ§Ã£o deste README em colaboraÃ§Ã£o assistiva.
